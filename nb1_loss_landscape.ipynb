{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daleas0120/townhall_tutorial/blob/main/nb1_loss_landscape.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzPJP3MXfFHe"
      },
      "source": [
        "# How to calculate a loss landscape\n",
        "\n",
        "Ashley S. Dale\n",
        "\n",
        "## Summary\n",
        "\n",
        "1. Train a small model on a toy dataset\n",
        "    - We will use the [Glass Identification Dataset](http://archive.ics.uci.edu/dataset/42/glass+identification) from UC Irvine Machine Learning Repository\n",
        "2. Calculate the Hessian of the model\n",
        "3. Calculate the eigenvalues and eigenvectors of the Hessian\n",
        "4. Calculate the loss landscape for the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IweH8iuQh2ln"
      },
      "outputs": [],
      "source": [
        "# install data repository\n",
        "%pip install ucimlrepo --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLDgdE93e8RM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "# Data Processing\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Model training & Hessian Calculation\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Hessian Eigenvectors and Values\n",
        "from numpy import linalg as LA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBrJfnVeiGVy"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFwQkWV6LUrl"
      },
      "source": [
        "`Double click this cell to edit`\n",
        "\n",
        "Add documentation to the notebook:\n",
        "\n",
        "Write a paragraph that describes the logic in the next two code cells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mmFTMILfgZl"
      },
      "outputs": [],
      "source": [
        "# load the dataset by running this cell\n",
        "glass_identification = fetch_ucirepo(id=42)\n",
        "\n",
        "# extract the refractive index and chemical formula information\n",
        "raw_data = glass_identification.data.features\n",
        "glass_kinds = glass_identification.data.targets\n",
        "\n",
        "# show a Pandas Dataframe table of data in the notebook\n",
        "# raw_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_w_9m00WlBO1"
      },
      "outputs": [],
      "source": [
        "X, y = raw_data.iloc[:, 1:], raw_data.iloc[:, 0]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce-bwKGiistF"
      },
      "source": [
        "## Define & Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmgkC5I6LUro"
      },
      "source": [
        "`Double click this cell to edit`\n",
        "\n",
        "Add documentation to the notebook:\n",
        "\n",
        "Write a paragraph that describes the logic in the next two code cells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDEL7GoqiI3B"
      },
      "outputs": [],
      "source": [
        "class LinearRegressionModel(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "      super(LinearRegressionModel, self).__init__()\n",
        "      self.linear = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "      out = self.linear(x)\n",
        "      return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kG-1iHwymen3"
      },
      "outputs": [],
      "source": [
        "model = LinearRegressionModel(X_train.shape[1], 1)\n",
        "print(model)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass\n",
        "    outputs = model(X_train_tensor)\n",
        "    loss = criterion(outputs, y_train_tensor)\n",
        "\n",
        "    # Backward and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward(retain_graph=True)\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.6f}')\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).reshape(-1, 1)\n",
        "    y_pred = model(X_test_tensor)\n",
        "\n",
        "    test_loss = criterion(y_pred, torch.tensor(y_test.values, dtype=torch.float32).reshape(-1, 1))\n",
        "    print(f'Test Loss: {test_loss.item():.6f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8Xl1WsFolg9"
      },
      "source": [
        "## Model Hessian Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "to8ldiZ-rI3O"
      },
      "outputs": [],
      "source": [
        "# Clear the existing model gradients\n",
        "model.zero_grad()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ffh9XvB1rLf0"
      },
      "outputs": [],
      "source": [
        "# Calculate the first gradients\n",
        "grads = torch.autograd.grad(loss, model.parameters(), create_graph=True, retain_graph=True)\n",
        "print(*(g.shape for g in grads))\n",
        "\n",
        "# Flatten the gradients into a single vector\n",
        "grads_flat = torch.cat([g.contiguous().view(-1) for g in grads])\n",
        "print(grads_flat.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-UYGZtqnnku"
      },
      "outputs": [],
      "source": [
        "# Create empty matrix to hold the gradient calculation\n",
        "num_params = grads_flat.numel()\n",
        "hessian = []\n",
        "\n",
        "# TODO: fill in the blanks in the code\n",
        "# for each gradient in the `grads_flat` vector\n",
        "for g_idx in grads_flat:\n",
        "\n",
        "    #TODO: get the gradient w.r.t. the gradient g_idx\n",
        "    grad2 =\n",
        "\n",
        "    #TODO: flatten the second derivative into a vector\n",
        "    grad2_flat =\n",
        "\n",
        "    #TODO: Add it to the hessian list\n",
        "    hessian.append(grad2_flat)\n",
        "\n",
        "hessian = torch.stack(hessian)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkBBwHpNqqsO"
      },
      "outputs": [],
      "source": [
        "# TODO: Visualize the Hessian Matrix by completing the plt.imshow() command\n",
        "plt.imshow()\n",
        "plt.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHIMVyKTsvU7"
      },
      "source": [
        "## Get the Hessian Eigenvalues and Eigenvectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lALQZUEDsAHj"
      },
      "outputs": [],
      "source": [
        "hessian = hessian.detach().numpy()\n",
        "\n",
        "# Solve for the eigenvalues and eigenvectors\n",
        "eigenvalues, eigenvectors = LA.eig(hessian)\n",
        "\n",
        "# Format and sort the eigenvalues and eigenvectors for use\n",
        "eigenvectors = [eigenvectors[:][i] for i in range(num_params)]\n",
        "eigenvalues = list([i] for i in eigenvalues)\n",
        "\n",
        "eigenvalues, eigenvectors = zip(*sorted(zip(eigenvalues, eigenvectors)))\n",
        "eigenvalues, eigenvectors = list(eigenvalues), list(eigenvectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sbmT3XlC5Tc"
      },
      "outputs": [],
      "source": [
        "# TODO: Plot the eigenvalues to check they are sorted; complete plt.plot() command\n",
        "plt.plot()\n",
        "plt.xlabel('ith Eigenvalue')\n",
        "plt.ylabel('Eigenvalue')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gl56GI5VtmPA"
      },
      "outputs": [],
      "source": [
        "# Convert eigenvectors to torch vectors\n",
        "eig1 = torch.tensor(eigenvectors[-1].reshape(1, -1), dtype=torch.float32)\n",
        "eig2 = torch.tensor(eigenvectors[-2].reshape(1, -1), dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGaKy-BauOge"
      },
      "source": [
        "## Calculate the Loss Landscape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgB8lIq-vx0M"
      },
      "outputs": [],
      "source": [
        "# Loss Landscape Hyperparameters\n",
        "loss_landscape_model = copy.deepcopy(model)\n",
        "n_steps = 100\n",
        "\n",
        "# shift model origin to be the middle of the plot\n",
        "loss_landscape_model.linear.weight.data = loss_landscape_model.linear.weight.data - (eig1[:, :-1]/2.) - (eig2[:, :-1]/2.)\n",
        "loss_landscape_model.linear.bias.data = loss_landscape_model.linear.bias.data - (eig1[:, -1]/2.) - (eig2[:, -1]/2.)\n",
        "\n",
        "# determine the update increment\n",
        "eig1_step = eig1/n_steps\n",
        "eig2_step = eig2/n_steps\n",
        "\n",
        "loss_landscape = []\n",
        "\n",
        "for _ in range(0, n_steps):\n",
        "  row = []\n",
        "\n",
        "  loss_landscape_model.linear.weight.data = loss_landscape_model.linear.weight.data + eig2_step[:, :-1]\n",
        "  loss_landscape_model.linear.bias.data = loss_landscape_model.linear.bias.data + eig2_step[:, -1]\n",
        "\n",
        "  for j in range(1, n_steps+1):\n",
        "    #TODO: add eig1_step weight values to the model weight parameters\n",
        "    loss_landscape_model.linear.weight.data =\n",
        "\n",
        "    #TODO: add eig1_step bias values to the model bias parameters\n",
        "    loss_landscape_model.linear.bias.data =\n",
        "\n",
        "    #TODO: get predictions with the updated loss_landscape_model for the X_test_tensor data\n",
        "    y_pred =\n",
        "\n",
        "    #TODO: calculate the loss between the y_pred variable and the y_test_tensor variables\n",
        "    loss =\n",
        "\n",
        "    # save the loss to the row of the loss landscape\n",
        "    row.append(loss.item())\n",
        "\n",
        "  loss_landscape.append(row)\n",
        "\n",
        "  # Rewind the model for the next row\n",
        "  loss_landscape_model.linear.weight.data = loss_landscape_model.linear.weight.data - j*eig1_step[:, :-1]\n",
        "  loss_landscape_model.linear.bias.data = loss_landscape_model.linear.bias.data - j*eig1_step[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbO9F-M8z8i8"
      },
      "outputs": [],
      "source": [
        "#TODO: Plot the loss landscape\n",
        "plt.imshow()\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbnw736VLUrt"
      },
      "source": [
        "# Open Questions\n",
        "\n",
        "1. What happens if the model is trained for more epochs? (reset the notebook kernel before doing this)\n",
        "1. If you change which eigenvectors are used for the calculation, what happens to the loss landscape?\n",
        "1. Add some noise to the dataset using a Gaussian random variable; how does affect the loss landscape?\n",
        "1. Can you reduce the model dimension so that there are no non-zero eigenvectors? (Hint: Consider removing redundant dataset features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krlkWVEfE6cT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}